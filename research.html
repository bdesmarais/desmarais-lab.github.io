<html>
<head>
<meta name="description" content="Homepage for Bruce Desmarais, description of work, research, teaching  and more.">
<meta name="Keywords" content="bruce desmarais, desmarais, bruce, unc, political science, assistant professor, political methodology, american politics, social networks, median regression, judicial politics, data mining, event history,computational social science">
<title>Bruce A. Desmarais - Assistant Professor - UMass Amherst - Political Science</title>

<link rel="icon" type="image/x-icon" href="favicon.ico">

<STYLE>
<!--
A{text-decoration:none}
-->
</STYLE>

<STYLE>
<!--
body { margin: 0; padding: 0; }
-->
</STYLE>


<style type="text/css">
<!--
.textborder {
border: 1px solid #000000;
}
-->

h2 {background-image: url(greyhead.jpg); 
	margin 0; 
	padding 0; 
	background-repeat: repeat-x}

</style>

</head>

<h2>
<body link="#881C1C" alink="#881C1C" vlink="#881C1C">
<div id="page">
<div id="content">
<div id="header">

<a href="index.html">&nbsp; Homepage</a>|
Research Projects|
<a href="desmarais_cv.pdf">CV</a> |
<a href="teaching.html">Teaching</a> 
</div>
<HR>
</h2>
<div id="main">
<table>
<tr>

<td valign="top" width="75%">


<table>
<tr>
<td valign="top" width="70%">
<h3>Bruce's Research Projects</h3>
<p>
</div>

<h4>Project Areas</h4>
<p>
<a href="#dissertation"><i>Dissertation</i></a><font size="2" face="Verdana"> The interdependence of choices rendered by political actors constitutes an essential feature of theories that span many areas of political science. For instance, it is hypothesized that members of a legislature will take voting cues from party leaders, the Chief Justice of the Supreme Court will vote with the majority in order to assign opinion authorship, and U.S. States will adopt policies similar to those of their neighbors. The methods that political scientists use to analyze data with interdependence were developed with an approach that treats interdependence as a nuisance - to be absorbed into a covariance matrix or averaged over - rather than a topic of primary interest, and are thus sub-optimal for testing theory about interdependence. In my dissertation I advance the methods that can be used to analyze interdependent discrete choices. In my first chapter, I describe in detail the problems with conventional methods of analyzing interdependent discrete choices. In the second chapter, I produce a method that can be used to learn patterns of interdependence without specifying a model more complicated than a standard logistic regression. In the third chapter I propose a  model in which the analyst specifies two equations - one explaining the direction of the individual choices and another explaining association among the actors in the dataset - while simulataneously accounting for the dependence between the two. The fourth and final chapter is purely substantive. Recognizing the inherent interdependence among Supreme Court decisions in their contributions to the body of law, I formulate a theory of a Court that targets an ideologically optimal body of law rather than optimal individual cases.</div></font>
<div id="smalltext">
<a href="#networks"><i>Political Network Analysis</i></a><font size="2" face="Verdana"> The observations in political network data are relationships between political actors (e.g. states, legislators and Supreme Court opinions). Moreover, especially in international relations, some of the most salient topics in the discipline - war, trade, international cooperation - can be represented as a network. Statistical inference on social networks poses interesting theoretical problems due to interdependence as well as computational problems attributable to political networks typically coming in the form of a large time series of giant adjacency matrices. Network analysis is a bugeoning field of inquiry across many disciplines and through a number of projects my coauthors and I hope to contribute to this development.</div></font>
<div id="smalltext"><p>
<a href="#robust"><i>Robust Estimation and Inference</i></a><font size="2" face="Verdana"> In political science we often <i>need</i> to make inappropriate assumptions about the data generating process in order to justify the use of regression models. It is helpful to understand what approaches to regression analysis are more robust to the complex interdependence in much political data and the resulting violation of identifying assumptions. I have projects on robust estimation of linear and duration regression models.</div></font>
<div id="smalltext"><p>
</p>



</td>


<td width="250" valign="top" >
<img src="web_photo.JPG" height="300" border=1>

<!--
<h5> </h5>
<div id="smalltext">
<p class="textborder">
<ul type = "square">
<li> </li>
<li>text</li>
<li>text</li>
</ul>

</p>
-->
</div>

</td>
</tr>
</table>

<p>&nbsp;</p>

<table>
<tr>

</tr>
</table>

<p>&nbsp;</p>


<h2><a name="dissertation">Dissertation</a></h2>
<tr><td>&nbsp;</td></tr>

<table cellpadding="10">
<tr>
<td>

<p>
<img src="judcites.jpg" height="240" border=1 >
</p>
<p>
<img src="judprlib.jpg" height="240" border=1 >
</p>
</td>
<td width="400">
<p><b><a href="Desmarais_Self_Correcting.pdf">The Self-Correcting U.S. Supreme Court</a></b></p>
<p><font size="2" face="Verdana">In contrast to the standard conception of a U.S. Supreme Court striving to produce ideologically optimal case outcomes, I theorize that the Court uses cases to construct an ideologically optimal body of law. The Court aims to influence behavior of legal entities such as administrative agencies and lower courts. These actors typically take direction from a collection of cases and not single, isolated decisions, thus creating an incentive for the Supreme Court to target an ideologically ideal body of law rather than ideal cases. A Court directly concerned with the integrated collection of cases uses current decisions to correct the ideological bias of past terms -- resulting in an inverse relationship between the ideological composition of past cases and the liberalism of the current term. Consistent with this implication, analysis of the 1953-2008 terms reveals an inverse relationship between the liberalism of past cases and that of the current term.</font>
</p>
</font>
</p>
</td>
</tr>
<tr><td>&nbsp;</td></tr>

<tr>
<td>
<p>
<img src="avally.jpg" height="240" border=1>
</p>
<p>
<img src="oth2item.jpg" height="240" border=1>
</p>
</td>
<td width="400">
<p><b>Lessons in Disguise: Multivariate Predictive Mistakes in Models of Repeated Collective Choice</b></p>
<p>
<font size="2" face="Verdana">Across the sub-fields of political science, much has been learned through the statistical analysis of repeated collective choices made by stable sets of actors -- voting in legislatures, decisions issued by courts of appeal, states considering conflict intervention, etc. There is more to gain from examining situations in which these models perform poorly, meaning they provide poor predictions about real data. I introduce a new prediction-error concept, the joint prediction error (JPE), which is a grouping of simultaneous individual outcomes that is poorly predicted by a model. Moving beyond just poorly predicted individual events, JPEs capture the intersecting information and inter-relationships missed by traditional diagnostics. I provide benchmarks for identifying joint prediction errors, and efficient algorithms to search for them. Analysis of JPEs is shown to improve empirical models from two published articles, one on U.S. Supreme Court voting, and another on the fulfillment of international defense alliances.</font>
</p>
</td>
</tr>

<tr><td>&nbsp;</td></tr>

</table>

<h2><a name="networks">Political Network Analysis</a></h2>
<tr><td>&nbsp;</td></tr>

<table cellpadding="10">
<tr>
<td>

<p>
<img src="mid.jpg" height="300" border=1 >
</p>
</td>
<td width="400">
<p><b>Inferential Network Analysis with Exponential Random Graph Models</b></p>
<p>with <a href="http://www.unc.edu/~skylerc/">Skyler Cranmer</a></p>
<font size="2" face="Verdana"> Methods for descriptive network analysis have reached statistical maturity and general acceptance across the social sciences in recent years. However, methods for statistical inference with network data remain fledgling by comparison. We evaluate and extend a new model for inference with network data, the Exponential Random Graph Model (ERGM), that simultaneously allows both inference on covariates and for arbitrarily complex network structures to be modeled. Our contributions are four fold: beyond introducing the ERGM and discussing its limitations, we extend the model to allow for the analysis of longitudinally observed networks, develop guidelines for analyzing highly dense and highly sparse networks, and show through applications that network-based inference can improve our understanding of political phenomena.</font>
</p>
</td>
</tr>
<tr><td>&nbsp;</td></tr>

<tr>
<td>
<p>
<img src="globe61.jpg" height="260" border=1>
</p>
</td>
<td width="400">
<p><b><a href ="alliance_network_formation.pdf">Toward a Network Theory of Alliance Formation</a></b></p>

<p> with Skyler Cranmer and <a href="http://www.unc.edu/~jhkirkla/">Justin Kirkland</a></p>

<p>
<font size="2" face="Verdana"> We propose the first network-based theory of alliance formation. Our theory suggests that, in addition to key state and dyad attributes already established by the literature, the evolution of the alliance network from any given point in time is largely determined by its structure. Specifically, we argue that closed triangles in the alliance network - where i is allied with j is allied with k is allied with i -  produce synergy effects in which node-level utility is greater than the sum of its dyadic parts. This idea can be generalized to n-node closure, and, when considered along with factors which make dyadic alliance formation more attractive such as military prowess and political compatibility, suggests that the network will evolve towards a state of several densely connected clusters of states with star-like groupings of states as an intermediary stage. To evaluate our theory, we use the SIENA model for longitudinal network analysis and find that the roles of our network effects are robustly supported by the data whereas the effects of non-network parameters vary substantially between periods of recent history. Our results indicate that network structure plays a more central role in the formation of alliance ties than has been previously understood in the literature.</font>
</p>
</td>
</tr>

<tr><td>&nbsp;</td></tr>

<tr>
<td>
<p>
<img src="statesys.jpg" height="350" border=1>
</p>
</td>
<td width="400">
<p><b>An Empirical Approach to International Relations that Unifies Multilevel Theory</b></p>
<p>with Skyler Cranmer and Elizabeth McKinney</p>
<p>
<font size="2" face="Verdana">
We propose an empirical framework for the study of international relations, which allows for the integration of state, dyad, and interdependent system-level theories. Because our technique allows for the integration of these three levels of analysis, which are not necessarily distinct theoretically and thus ought not to be distinct empirically, we call our technique "unified relational analysis". We describe the nature and extent of the problems with analysis at any one level - focusing specifically on independence issues in dyadic analyses - and introduce our proposed solution; a model from the network literature called the exponential random graph model, which we extend to longitudinal networks - a ubiquitous structure in international relations. We then perform a unified analysis of the international defense alliance network, which integrates covariates related to each of the three levels of analysis: democratization and lateral pressure (state-level), joint democracy and trade (dyadic- level), and system-level interdependence (the formation of dense communities). We demonstrate the theoretical appeal of integrating the three levels of analysis in the context of an interdependent network, and show that our approach permits the accurate forecasting of the evolution of the alliance network.</font>
</pos>
</td>
</tr>

<tr><td>&nbsp;</td></tr>


<tr>
<td>
<p>
<img src="hrace10.jpg" height="350" border=1>
</p>
</td>
<td width="400">
<p><b>Race, Gender and Relational Determinants of Cosponsorship in the U.S. House</b></p>
<p>with Skyler Cranmer and <a href="http://jhfowler.ucsd.edu/">James Fowler</a></p>
<p>
<font size="2" face="Verdana"> Recognizing its importance in the legislative process, a large body of scholarship on cosponsorship has emerged. The empirical end of this work has thoroughly examined characteristics and motivations of the cosponsors, which we argue limits attention to one side of a transaction between the sponsor and cosponsor. We utilize network analysis to extend inference on cosponsorship behavior to dyadic, or relational factors on sponsor-cosponsor pairs. Due to the presence of strong organizing forces such as the Congressional Black Caucus, prejudice in other legislative processes, and a ubiquitous finding in the social sciences that people tend towards within-race and gender interaction, we expect that race and gender based assortative mixing (AM) characterize the U.S. House Cosponsorship network. Using the full Cosponsorship networks from the 97th - 108th Houses, we find strong support for this hypothesis. We also re-examine a number of previous findings on the cosponsorship process.</font>
</p>
</td>
</tr>

<tr><td>&nbsp;</td></tr>

<tr>
<td>
<p>
<img src="circ108.jpg" height="350" border=1>
</p>
</td>
<td width="400">
<p><b>Longitudinal Analysis of Social Networks: A General Model and Application to Cosponsorship in the U.S. Senate</b></p>
<p>with Skyler Cranmer</p>
<p>
<font size="2" face="Verdana"> The study of relationship formation is central to our understanding of many political processes including international conflict and alliance formation, the progress of the law through case-to-case citations, and collaboration in legislative institutions. The exponential random graph model (ERGM) is a tool for statistical inference on the processes that generate a network, including the effects of dyad and actor-level covariates and influence between the relationships (e.g. reciprocity and community formation). The ERGM is thoroughly developed for the study of a single observation of the network, yet most networks of interest to political scientists (e.g. the examples above) occur in multiple iterations over time. We present the Temporal ERGM (TERGM) -- an extention of the ERGM for modeling and forecasting the evolution of a network. We demonstrate its use through the analysis of cosponsorship in the U.S. Senate from the 94th to the 108th Congress.</font>
</p>
</td>
</tr>

<tr><td>&nbsp;</td></tr>

</table>

<h2><a name="robust">Robust Estimation and Inference</a></h2>
<tr><td>&nbsp;</td></tr>

<table cellpadding="10">
<tr>
<td>

<p>
<img src="mr.jpg" height="350" border=1 >
</p>
</td>
<td width="400">
<p><b>Efficient Estimation of the Linear Model: Choosing Between Conditional-Mean and Conditional-Median Methods</b></p>
<p>with <a href ="http://www.unc.edu/~jjharden/">Jeff Harden</a></p>
<p><font size="2" face="Verdana">When political scientists analyze data with a strictly linear hypothesis and a continuous dependent variable, model fitting usually proceeds by ordinary least squares (OLS) or one of its variants. However, OLS is not always the most efficient approach to estimating parameters of the linear model. Here we compare OLS to another type of linear estimation method, Median Regression (MR), which is known to estimate parameters more efficiently than OLS when the error term is drawn from a heavy-tailed distribution. We show how standard model selection techniques can be used to choose between OLS and MR. Then through several replications of past work, we highlight instances in political science in which MR parameter estimates outperform those of OLS and lead to substantively different results. We conclude that MR can be a useful tool for political science. </font>
</p>
</td>
</tr>
<tr><td>&nbsp;</td></tr>

<tr>
<td>
<p>
<img src="bseff.jpg" height="320" border=1>
</p>
</td>
<td width="400">
<p><b><a href="Desmarais_ICDurs.pdf">Discrete Measurement of Time and Interval Censoring in Event History Analysis</a></b></p>
<p>
<font size="2" face="Verdana">
A problem in event history analysis is that time is measured imprecisely. Events are <i>typically</i> known to occur within discrete time units (e.g. day, month or year). Discrete measurement of the start and end time of an event leads to a known interval within which the event duration falls. The event duration is <i>interval censored</i>. When ignored, interval censoring is shown to introduce considerable bias to parameter estimates and heighten the risk of inference errors. I show that treating the duration as an interval reduces bias and improves the performance of hypothesis tests. Replications of analyses from four political science articles in leading journals demonstrate that substantive inferences depend on the use of appropriate methods for interval censored duration data. I also develop a software package that can be used to estimate the Cox proportional hazards model with interval censoring.
</p>
</td>
</tr>

<tr><td>&nbsp;</td></tr>


</table>


</div>
</div>
</div>


</body>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-13145215-1");
pageTracker._trackPageview();
} catch(err) {}</script>

</html>

