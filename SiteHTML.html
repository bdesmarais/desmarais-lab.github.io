<html>
<head>
<meta name="Keywords" content="desmarais, bruce, unc, political science, graduate student, candidate, political methodology, american politics, social networks, median regression, judicial politics, data mining, event history">
<link rel="SHORTCUT ICON" href="images/CornellBigRed.png"> 
<title>Bruce Desmarais - Ph.D. Candidate - UNC Chapel Hill - Political Science</title>
</head>


<body>
<div id="page">
<div id="content">

<div id="header">
Homepage |

<a href="publications.html">Research</a> |
<a href="Bruce_Desmarais_cv.pdf">CV</a> |
<a href="Bruce_Desmarais_cv.pdf">Software, Code and Data</a> | 
<a href="contact.html">Interesting Links</a> 
</div>


<div id="main">
<table>
<tr>

<td valign="top" width="75%">


<table>
<tr>
<td valign="top" width="70%">
<h3>Bruce Desmarais</h3>
<p>
<div id="smalltext">
Ph.D. Candidate<br>
UNC Chapel Hill<br>
Department of Political Science<br>


<br>
<a href="contact.html">Contact info</a>
</div>

<h4>Research interests</h4>
<p>
<i>American Politics:</i> U.S. Supreme Court, Congressional Cosponsorship, Roll-Call Voting, Official Secrecy.
<div id="smalltext"> 
<i>Political Methodology:</i> Social Network Analysis, Event History Modeling, Robust Estimation, Machine Learning.</div>
</p>



<h4>Projects</h4>
<p>
In the past, I have developed machine learning algorithms
to solve challenging problems.  In particular, I had
developed <a href="http://make3d.stanford.edu">Make3D</a>, 
an algorithm that can make 3D models from a <i>single</i> standard
digital picture. My algorithms have enabled robots to 
do various tasks, such as avoid obstacles while driving
at high speeds, unload items from a dishwasher, etc.
</p>
<p>
I am in the process of starting new research projects
in the areas of machine learning, robotics and online
video collections.  If you're a student (<i>graduate</i> or 

<i>undergraduate</i>) at Cornell University and interested 
in getting involved, feel free to get in touch with me.
</p>


</td>


<td width="250" valign="top" >
<img src="images/ashutosh_saxena.jpg" height="250">
<!--<img src="images/saxena_ashutosh.jpg" height="150">-->

<h5>Announcements</h5>
<div id="smalltext">
Make3D and Grasping featured in Nilsson's book <a href="http://www.cambridge.org/us/catalogue/catalogue.asp?isbn=9780521122931">"The Quest for Artificial Intelligence"</a>, that promises to be a definitive history of the field.<br /><br />

My work on robotic grasping featured in Discovery Science Channel on Jan 19 (10pm EST). The physics of the impossible: How to build an intelligent robot.<br /><br />
Arjun Prakash and Jigar Shah awarded ELI undergraduate research award.<br /><br />
Soundararaj and Sujeeth's paper on autonomous 
indoor helicopter flights was accepted in IROS 2009.
<br /><br />
</div>

</td>
</tr>
</table>

<p>&nbsp;</p>

<table>
<tr>

</tr>
</table>

<p>&nbsp;</p>


<h2>SELECTED PROJECTS</h2>
<p><a href="http://www.cs.cornell.edu/~asaxena/projects.html">(Click here to see all projects.)</a></p>

<tr><td>&nbsp;</td></tr>

<table cellpadding="10">
<tr>
<td>

<p>
<a href="http://make3d.stanford.edu">
<img src="images/make3dexample.jpg" height="120" >
<img src="images/mountain_snapshot_small.jpg" height="120" >
</a>
</p>
</td>
<td width="400">
<p><b><a href="http://make3d.stanford.edu">Make3D</a>: Single Image Depth Perception</b></p>
<p>Learning algorithms to predict depth and infer 3-d models, given just a <i>single still</i> image.
Applications included creating immersive 3-d experience from users' photos, 
improving performance of stereovision, 
creating large-scale models from a few images, robot navigation, etc.
Tens of thousands of users have converted their single photographs into 3D models.
<br>
<div id="smalltext">Selected Papers: 

<a href="learningdepth/NIPS_LearningDepth.pdf">NIPS'05</a>, 
<a href="learningdepth/saxena_ijcv07_learningdepth.pdf">IJCV'07</a>, 
<a href="reconstruction3d/saxena_iccv_3drr07_learning3d.pdf">ICCV-3dRR'07</a>, 
<a href="reconstruction3d/Saxena_depthperception_aaai08.pdf">AAAI-Nectar'08</a>,
<a href="reconstruction3d/saxena_make3d_learning3dstructure.pdf">IEEE-PAMI'08</a>.
<a href="ccm/">NIPS'08</a>.<br>
Research/Code/Data: <a href="learningdepth/">2005</a>, <a href="reconstruction3d">2007</a>, <a href="learningdepth/data.html">data</a>.<br>

Online demo: <a href="http://make3d.stanford.edu">Make3D.Stanford.edu</a>.<br />
<a href="media.html">
Popular Press: New Scientist, Technology Review, Scientific Computing, NTT (Japan).</a>

</div>
</p>
</td>
</tr>

<tr><td>&nbsp;</td></tr>

<tr>
<td width="450">

<p>
<a href="learninggrasp/">
<img src="images/dishwashergrasping.jpg" height="150" >
<img src="images/clutteredgrasping.jpg" height="150" >
<img src="openingnewdoors/openingnewdoorsteaser.jpg" height="150" >
</a>
</p>
</td>
<td width="400">
<p><b>Learning Mobile Robot Manipulation</b></p>
<p>Learning algorithms to predict robotic grasps, even for objects of types never seen 
before by the robot.  Applied to tasks such as unloading items from a dishwasher, clearing 
up a cluttered table, opening new doors, etc.
<div id="smalltext">Selected Papers: 
<a href="learninggrasp/NIPS_LearningGrasp.pdf">NIPS'06</a>, 
<a href="learninggrasp/IJRR_saxena_etal_roboticgraspingofnovelobjects.pdf">IJRR'08</a>, 

<a href="publications.html">AAAI'08a</a>, <a href="publications.html">AAAI'08b</a>.<br>
Research/Code/Data: <a href="learninggrasp/">Dishwasher</a>, <a href="clutteredgrasping/">Cluttered (Barrett)</a>, <a href="openingnewdoors/">Opening New Doors</a>.<br>
Details: <a href="http://stair.stanford.edu">STAIR</a>, <a href="stairmanipulation">Manipulation group</a>.<br />

Popular Press: New York Times, Wired Magazine, NBC, ABC, BBC. 
</div>
</p>
</td>
</tr>

<tr><td>&nbsp;</td></tr>

<tr>
<td>
<p>
<a href="rccar/">
<img src="rccar/car_small.jpg" height="140" >
<img src="images/carviewteaser.jpg" height="140" >
</a>
<a href="helicopter/">
<img src="helicopter/helicopter_pic_small.jpg" height="100" >

</a>
</p>
</td>
<td width="400">
<p><b>Visual Navigation: <a href="rccar/">High speed obstacle avoidance</a></b></p>
<p>Use monocular depth perception and reinforcement learning 
techniques to drive a small rc-car at high speeds in unstructured
environments.  Also fly a indoor helicopter autonomously using
a single onboard camera.
<div id="smalltext">Selected Papers: <a href="rccar/ICML_ObstacleAvoidance.pdf">ICML'05</a>, 
<a href="learningdepth/saxena_ijcv07_learningdepth.pdf">IJCV'07</a>.<br>
Research/Code/Data: <a href="rccar/">here</a>.<br>

Video: <a href="http://www.youtube.com/watch?v=UZ7_ED9g4FY">Youtube</a>.<br />
Popular Press: KTVU news, New Scientist.
</div>
</p>
</td>
</tr>

<tr><td>&nbsp;</td></tr>

</table>

</div>
</div>
</div>


<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-2378673-1";
urchinTracker();
</script>

</body>
</html>

